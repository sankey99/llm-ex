{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankey99/llm-ex/blob/master/Week_3_Day_1_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 3 Day 1\n",
        "\n",
        "For this example of using Colab, I use a powerful GPU box to generate a cool image!\n",
        "\n",
        "## Important note\n",
        "\n",
        "This first example needs an A100 box to run, as it uses the groundbreaking FLUX-1 model. That may cost a couple of dollars to run, so I'm saving the results here so you can see the output without needing to use an A100. But if you don't mind the spend then it's a lot of fun!\n",
        "\n",
        "You can also substitute in a cheaper model if you'd prefer, and I've given an example at the bottom of this colab that runs on a free T4.  \n",
        "To try out the free image generation\n",
        "\n",
        "## One more note\n",
        "\n",
        "You will get an angry error from pip when you run the next cell, complaining about an incompatible version of fsspec. Ignore the error - we need that version!"
      ],
      "metadata": {
        "id": "JTygxy-RAn1f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwOCFTG8SrsD"
      },
      "outputs": [],
      "source": [
        "# Disregard the error that pip gives you when you run this - all should be well!\n",
        "\n",
        "!pip install -q diffusers transformers accelerate bitsandbytes datasets fsspec==2023.9.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Note\n",
        "\n",
        "I didn't mention this in the lecture, but you may need to log in to the HuggingFace hub if you've not done so before.\n",
        "\n",
        "1. If you haven't already done so, create a **free** HuggingFace account at https://huggingface.co and navigate to Settings from the user menu on the top right. Then Create a new API token, giving yourself write permissions.  \n",
        "\n",
        "**IMPORTANT** when you create your HuggingFace API key, please be sure to select read/write permissions for your key by clicking on the WRITE tab, otherwise you may get problems later.\n",
        "\n",
        "2. Back here in colab, press the \"key\" icon on the side panel to the left, and add a new secret:  \n",
        "  In the name field put `HF_TOKEN`  \n",
        "  In the value field put your actual token: `hf_...`  \n",
        "  Ensure the notebook access switch is turned ON.\n",
        "\n",
        "3. Execute the cell below to log in. You'll need to do this on each of your colabs. It's a really useful way to manage your secrets without needing to type them into colab. There's also a shortcut to simply overwrite the line below with:  \n",
        "`hf_token = \"hf_....\"`  \n",
        "But this isn't a best practice, as you'd have to be careful not to share the colab. And one of the great things about colabs is that you can share them!"
      ],
      "metadata": {
        "id": "TV8_hr1rCGUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "ZR-wgFH-CKtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This next cell will only work on a powerful GPU box like an A100\n",
        "\n",
        "But at the bottom of the colab is an example that will run on a free T4!\n",
        "\n",
        "(The purpose of this colab is to show off how you can connect to different GPUs and what they are capable of, rather than the specifics of image generation.)"
      ],
      "metadata": {
        "id": "yv1Iv0vjPlI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import FluxPipeline\n",
        "\n",
        "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16).to(\"cuda\")\n",
        "generator = torch.Generator(device=\"cuda\").manual_seed(0)\n",
        "prompt = \"A futuristic class full of students learning AI coding in the surreal style of Salvador Dali\"\n",
        "\n",
        "# Generate the image using the GPU\n",
        "image = pipe(\n",
        "    prompt,\n",
        "    guidance_scale=0.0,\n",
        "    num_inference_steps=4,\n",
        "    max_sequence_length=256,\n",
        "    generator=generator\n",
        ").images[0]\n",
        "\n",
        "image.save(\"surreal.png\")"
      ],
      "metadata": {
        "id": "qw_WV7SgTWBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "\n",
        "# Display the image inline\n",
        "display(image)"
      ],
      "metadata": {
        "id": "BAMucdhzStSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "import soundfile as sf\n",
        "import torch\n",
        "\n",
        "synthesiser = pipeline(\"text-to-speech\", \"microsoft/speecht5_tts\", device='cuda')\n",
        "\n",
        "embeddings_dataset = load_dataset(\"matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
        "\n",
        "speaker_embedding = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
        "\n",
        "speech = synthesiser(\"Hi to an artificial intelligence engineer on the way to mastery!\", forward_params={\"speaker_embeddings\": speaker_embedding})\n",
        "\n",
        "sf.write(\"speech.wav\", speech[\"audio\"], samplerate=speech[\"sampling_rate\"])"
      ],
      "metadata": {
        "id": "Gp-dpBUSsK07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "# Play the generated audio\n",
        "Audio(\"speech.wav\")"
      ],
      "metadata": {
        "id": "Bv3p8lBhzDSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To run image generation on a free T4 box\n",
        "\n",
        "Please run the code below. The results are not as impressive as the Flux model, but it runs quickly..\n",
        "\n"
      ],
      "metadata": {
        "id": "WINPO9esOdPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q diffusers"
      ],
      "metadata": {
        "id": "EUFijpFFyDZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import AutoPipelineForText2Image\n",
        "import torch\n",
        "\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sd-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"A futuristic class full of students learning AI coding in a surreal style\"\n",
        "image = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=0.0).images[0]\n"
      ],
      "metadata": {
        "id": "5Ld6DpLkW0fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "\n",
        "# Display the image inline\n",
        "display(image)"
      ],
      "metadata": {
        "id": "cFrLegF766F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m47JcY6868bY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}